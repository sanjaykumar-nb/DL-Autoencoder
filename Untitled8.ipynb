{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxi58kI6FDTXEKUSO5FSum",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjaykumar-nb/DL-Autoencoder/blob/main/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G63NN8wUVDfc",
        "outputId": "dcac7d99-e379-4cea-f1a9-968a7515e568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 6.07MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 160kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.52MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.82MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: SANJAYKUMAR N B\n",
            "Register Number: 212223230189\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 14, 14]             160\n",
            "              ReLU-2           [-1, 16, 14, 14]               0\n",
            "            Conv2d-3             [-1, 32, 7, 7]           4,640\n",
            "              ReLU-4             [-1, 32, 7, 7]               0\n",
            "   ConvTranspose2d-5           [-1, 16, 14, 14]           4,624\n",
            "              ReLU-6           [-1, 16, 14, 14]               0\n",
            "   ConvTranspose2d-7            [-1, 1, 28, 28]             145\n",
            "           Sigmoid-8            [-1, 1, 28, 28]               0\n",
            "================================================================\n",
            "Total params: 9,569\n",
            "Trainable params: 9,569\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.13\n",
            "Params size (MB): 0.04\n",
            "Estimated Total Size (MB): 0.17\n",
            "----------------------------------------------------------------\n",
            "Name: SANJAYKUMAR N B\n",
            "Register Number: 212223230189\n",
            "Epoch [1/5], Loss: 0.0910\n",
            "Epoch [2/5], Loss: 0.0160\n",
            "Epoch [3/5], Loss: 0.0149\n"
          ]
        }
      ],
      "source": [
        "# Autoencoder for Image Denoising using PyTorch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "# Transform: Normalize and convert to tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load MNIST dataset\n",
        "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Add noise to images\n",
        "def add_noise(inputs, noise_factor=0.5):\n",
        "    noisy = inputs + noise_factor * torch.randn_like(inputs)\n",
        "    return torch.clamp(noisy, 0., 1.)\n",
        "\n",
        "# Denoising Autoencoder model\n",
        "class DenoisingAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DenoisingAutoencoder, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),  # [B, 16, 14, 14]\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1), # [B, 32, 7, 7]\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),  # [B, 16, 14, 14]\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),   # [B, 1, 28, 28]\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model, loss function and optimizer\n",
        "model = DenoisingAutoencoder().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Print model summary\n",
        "print(\"Name: SANJAYKUMAR N B\")\n",
        "print(\"Register Number: 212223230189\")\n",
        "summary(model, input_size = (1, 28, 28))\n",
        "\n",
        "# Train the autoencoder\n",
        "def train(model, loader, criterion, optimizer, epochs=5):\n",
        "    model.train()\n",
        "\n",
        "    print(\"Name: SANJAYKUMAR N B\")\n",
        "    print(\"Register Number: 212223230189\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for images, _ in loader:\n",
        "            images = images.to(device)\n",
        "            noisy_images = add_noise(images).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(noisy_images)\n",
        "            loss = criterion(outputs, images)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(loader):.4f}\")\n",
        "\n",
        "# Evaluate and visualize\n",
        "def visualize_denoising(model, loader, num_images=10):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, _ in loader:\n",
        "            images = images.to(device)\n",
        "            noisy_images = add_noise(images).to(device)\n",
        "            outputs = model(noisy_images)\n",
        "            break\n",
        "\n",
        "    images = images.cpu().numpy()\n",
        "    noisy_images = noisy_images.cpu().numpy()\n",
        "    outputs = outputs.cpu().numpy()\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(18, 6))\n",
        "\n",
        "    for i in range(num_images):\n",
        "        # Original\n",
        "        ax = plt.subplot(3, num_images, i + 1)\n",
        "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
        "        ax.set_title(\"Original\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        # Noisy\n",
        "        ax = plt.subplot(3, num_images, i + 1 + num_images)\n",
        "        plt.imshow(noisy_images[i].squeeze(), cmap='gray')\n",
        "        ax.set_title(\"Noisy\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        # Denoised\n",
        "        ax = plt.subplot(3, num_images, i + 1 + 2 * num_images)\n",
        "        plt.imshow(outputs[i].squeeze(), cmap='gray')\n",
        "        ax.set_title(\"Denoised\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run training and visualization\n",
        "train(model, train_loader, criterion, optimizer, epochs=5)\n",
        "visualize_denoising(model, test_loader)\n",
        "\n"
      ]
    }
  ]
}